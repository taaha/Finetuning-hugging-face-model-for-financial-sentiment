{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"336d2cd5-0cf7-4f19-a1ed-ecc9b41a75c8","_cell_guid":"3b53bcec-ee06-470a-b8f2-afb5b24849fa","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-02-19T16:09:16.223667Z","iopub.execute_input":"2023-02-19T16:09:16.223981Z","iopub.status.idle":"2023-02-19T16:09:16.240706Z","shell.execute_reply.started":"2023-02-19T16:09:16.223955Z","shell.execute_reply":"2023-02-19T16:09:16.239723Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/financial-sentiment-analysis/data.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install transformers","metadata":{"execution":{"iopub.status.busy":"2023-02-19T16:09:16.242758Z","iopub.execute_input":"2023-02-19T16:09:16.243506Z","iopub.status.idle":"2023-02-19T16:09:28.816661Z","shell.execute_reply.started":"2023-02-19T16:09:16.243466Z","shell.execute_reply":"2023-02-19T16:09:28.815315Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.20.1)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.12.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.28.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.7.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.10.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (23.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.8.1)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.12.7)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.11)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.3)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.1.1)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"### Loading Data","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/financial-sentiment-analysis/data.csv')\nprint(data.shape)\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2023-02-19T16:09:28.820714Z","iopub.execute_input":"2023-02-19T16:09:28.821061Z","iopub.status.idle":"2023-02-19T16:09:28.878919Z","shell.execute_reply.started":"2023-02-19T16:09:28.821022Z","shell.execute_reply":"2023-02-19T16:09:28.877415Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"(5842, 2)\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                            Sentence Sentiment\n0  The GeoSolutions technology will leverage Bene...  positive\n1  $ESI on lows, down $1.50 to $2.50 BK a real po...  negative\n2  For the last quarter of 2010 , Componenta 's n...  positive\n3  According to the Finnish-Russian Chamber of Co...   neutral\n4  The Swedish buyout firm has sold its remaining...   neutral","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sentence</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>The GeoSolutions technology will leverage Bene...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>$ESI on lows, down $1.50 to $2.50 BK a real po...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>For the last quarter of 2010 , Componenta 's n...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>According to the Finnish-Russian Chamber of Co...</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The Swedish buyout firm has sold its remaining...</td>\n      <td>neutral</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data['Sentiment'].value_counts().plot(kind = 'bar')","metadata":{"execution":{"iopub.status.busy":"2023-02-19T16:09:28.881211Z","iopub.execute_input":"2023-02-19T16:09:28.881613Z","iopub.status.idle":"2023-02-19T16:09:29.135475Z","shell.execute_reply.started":"2023-02-19T16:09:28.881577Z","shell.execute_reply":"2023-02-19T16:09:29.134332Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"<AxesSubplot:>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":"### Replacing labels with numerical values","metadata":{}},{"cell_type":"code","source":"data['Sentiment'].replace(['negative', 'neutral', 'positive'], \n                          [0, 1, 2], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-02-19T16:09:29.137485Z","iopub.execute_input":"2023-02-19T16:09:29.138180Z","iopub.status.idle":"2023-02-19T16:09:29.148117Z","shell.execute_reply.started":"2023-02-19T16:09:29.138142Z","shell.execute_reply":"2023-02-19T16:09:29.146552Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"### Finding max length of strings in data","metadata":{}},{"cell_type":"code","source":"print(data.Sentence.str.len().max())","metadata":{"execution":{"iopub.status.busy":"2023-02-19T16:09:29.351845Z","iopub.execute_input":"2023-02-19T16:09:29.352254Z","iopub.status.idle":"2023-02-19T16:09:29.362257Z","shell.execute_reply.started":"2023-02-19T16:09:29.352217Z","shell.execute_reply":"2023-02-19T16:09:29.361137Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"315\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\nimport torch\nfrom transformers import TrainingArguments, Trainer\nfrom transformers import BertTokenizer, BertForSequenceClassification","metadata":{"execution":{"iopub.status.busy":"2023-02-19T16:09:29.364295Z","iopub.execute_input":"2023-02-19T16:09:29.365361Z","iopub.status.idle":"2023-02-19T16:09:29.372261Z","shell.execute_reply.started":"2023-02-19T16:09:29.365320Z","shell.execute_reply":"2023-02-19T16:09:29.371071Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"### Downloading tokenizer and model","metadata":{}},{"cell_type":"code","source":"from transformers import BertTokenizer, BertForSequenceClassification\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nmodel = BertForSequenceClassification.from_pretrained('bert-base-uncased',num_labels=3)\nprint(model.classifier.parameters)","metadata":{"execution":{"iopub.status.busy":"2023-02-19T16:09:29.376913Z","iopub.execute_input":"2023-02-19T16:09:29.377799Z","iopub.status.idle":"2023-02-19T16:09:49.361173Z","shell.execute_reply.started":"2023-02-19T16:09:29.377758Z","shell.execute_reply":"2023-02-19T16:09:49.360105Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35a05f44080d4436bb2f2613e068e8b4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9de76ba64ecc4b938442cbf6e8fbcc76"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7ca4676658a4d04b737993582e07a35"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1338c5d845d946db9eb05f726c05d63b"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"<bound method Module.parameters of Linear(in_features=768, out_features=3, bias=True)>\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer","metadata":{"execution":{"iopub.status.busy":"2023-02-19T16:09:49.363058Z","iopub.execute_input":"2023-02-19T16:09:49.363474Z","iopub.status.idle":"2023-02-19T16:09:49.376664Z","shell.execute_reply.started":"2023-02-19T16:09:49.363434Z","shell.execute_reply":"2023-02-19T16:09:49.375436Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"PreTrainedTokenizer(name_or_path='bert-base-uncased', vocab_size=30522, model_max_len=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"},"metadata":{}}]},{"cell_type":"code","source":"model","metadata":{"execution":{"iopub.status.busy":"2023-02-19T16:09:49.378142Z","iopub.execute_input":"2023-02-19T16:09:49.378948Z","iopub.status.idle":"2023-02-19T16:09:50.320686Z","shell.execute_reply.started":"2023-02-19T16:09:49.378900Z","shell.execute_reply":"2023-02-19T16:09:50.319342Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"BertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=3, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"model = model.to('cuda')","metadata":{"execution":{"iopub.status.busy":"2023-02-19T16:09:50.322646Z","iopub.execute_input":"2023-02-19T16:09:50.323145Z","iopub.status.idle":"2023-02-19T16:09:52.287817Z","shell.execute_reply.started":"2023-02-19T16:09:50.323107Z","shell.execute_reply":"2023-02-19T16:09:52.286829Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"sample_data = data['Sentence'][0]\nprint(sample_data)","metadata":{"execution":{"iopub.status.busy":"2023-02-19T16:09:52.289367Z","iopub.execute_input":"2023-02-19T16:09:52.289765Z","iopub.status.idle":"2023-02-19T16:09:52.295953Z","shell.execute_reply.started":"2023-02-19T16:09:52.289726Z","shell.execute_reply":"2023-02-19T16:09:52.294742Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"The GeoSolutions technology will leverage Benefon 's GPS solutions by providing Location Based Search Technology , a Communities Platform , location relevant multimedia content and a new and powerful commercial model .\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer(sample_data, padding=True, truncation=True, max_length=512)","metadata":{"execution":{"iopub.status.busy":"2023-02-19T16:09:52.297753Z","iopub.execute_input":"2023-02-19T16:09:52.298554Z","iopub.status.idle":"2023-02-19T16:09:52.316127Z","shell.execute_reply.started":"2023-02-19T16:09:52.298506Z","shell.execute_reply":"2023-02-19T16:09:52.314724Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [101, 1996, 20248, 19454, 13700, 2015, 2974, 2097, 21155, 3841, 12879, 2239, 1005, 1055, 14658, 7300, 2011, 4346, 3295, 2241, 3945, 2974, 1010, 1037, 4279, 4132, 1010, 3295, 7882, 14959, 4180, 1998, 1037, 2047, 1998, 3928, 3293, 2944, 1012, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"},"metadata":{}}]},{"cell_type":"markdown","source":"### Train Test Split","metadata":{}},{"cell_type":"code","source":"X = list(data[\"Sentence\"])\ny = list(data[\"Sentiment\"])\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2,stratify=y)\nX_train_tokenized = tokenizer(X_train, padding=True, truncation=True, max_length=512)\nX_val_tokenized = tokenizer(X_val, padding=True, truncation=True, max_length=512)","metadata":{"execution":{"iopub.status.busy":"2023-02-19T16:10:22.361994Z","iopub.execute_input":"2023-02-19T16:10:22.362390Z","iopub.status.idle":"2023-02-19T16:10:26.659858Z","shell.execute_reply.started":"2023-02-19T16:10:22.362336Z","shell.execute_reply":"2023-02-19T16:10:26.658807Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"X_train_tokenized.keys()","metadata":{"execution":{"iopub.status.busy":"2023-02-19T16:11:50.476302Z","iopub.execute_input":"2023-02-19T16:11:50.476724Z","iopub.status.idle":"2023-02-19T16:11:50.485541Z","shell.execute_reply.started":"2023-02-19T16:11:50.476693Z","shell.execute_reply":"2023-02-19T16:11:50.484455Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"},"metadata":{}}]},{"cell_type":"code","source":"print(X_train_tokenized['input_ids'][0])","metadata":{"execution":{"iopub.status.busy":"2023-02-19T16:12:36.840171Z","iopub.execute_input":"2023-02-19T16:12:36.840526Z","iopub.status.idle":"2023-02-19T16:12:36.846337Z","shell.execute_reply.started":"2023-02-19T16:12:36.840497Z","shell.execute_reply":"2023-02-19T16:12:36.845082Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"[101, 3481, 2819, 2036, 2038, 1037, 10851, 8406, 1999, 7855, 1056, 2290, 2243, 1011, 1015, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","output_type":"stream"}]},{"cell_type":"code","source":"print(X_train_tokenized['attention_mask'][0])","metadata":{"execution":{"iopub.status.busy":"2023-02-19T16:12:38.491836Z","iopub.execute_input":"2023-02-19T16:12:38.492192Z","iopub.status.idle":"2023-02-19T16:12:38.497935Z","shell.execute_reply.started":"2023-02-19T16:12:38.492163Z","shell.execute_reply":"2023-02-19T16:12:38.496807Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Creating torch dataset","metadata":{}},{"cell_type":"code","source":"class Dataset(torch.utils.data.Dataset):\n    def __init__(self, encodings, labels=None):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        if self.labels:\n            item[\"labels\"] = torch.tensor(self.labels[idx])\n        return item\n\n    def __len__(self):\n        return len(self.encodings[\"input_ids\"])","metadata":{"execution":{"iopub.status.busy":"2023-02-19T16:15:44.928269Z","iopub.execute_input":"2023-02-19T16:15:44.929400Z","iopub.status.idle":"2023-02-19T16:15:44.936800Z","shell.execute_reply.started":"2023-02-19T16:15:44.929337Z","shell.execute_reply":"2023-02-19T16:15:44.935482Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"train_dataset = Dataset(X_train_tokenized, y_train)\nval_dataset = Dataset(X_val_tokenized, y_val)","metadata":{"execution":{"iopub.status.busy":"2023-02-19T16:16:34.928965Z","iopub.execute_input":"2023-02-19T16:16:34.929327Z","iopub.status.idle":"2023-02-19T16:16:34.933847Z","shell.execute_reply.started":"2023-02-19T16:16:34.929296Z","shell.execute_reply":"2023-02-19T16:16:34.932840Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"train_dataset[5]","metadata":{"execution":{"iopub.status.busy":"2023-02-19T16:16:45.373325Z","iopub.execute_input":"2023-02-19T16:16:45.373938Z","iopub.status.idle":"2023-02-19T16:16:45.393163Z","shell.execute_reply.started":"2023-02-19T16:16:45.373903Z","shell.execute_reply":"2023-02-19T16:16:45.392134Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"{'input_ids': tensor([  101,  1996,  3643,  1997,  1996,  3813,  1005,  1055, 13116,  9583,\n          3445,  2011,  7367,  2243,  1017,  1012,  1020, 24869,  1012,   102,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0]),\n 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0]),\n 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n         0, 0, 0, 0, 0, 0]),\n 'labels': tensor(2)}"},"metadata":{}}]},{"cell_type":"code","source":"def compute_metrics(p):\n    print(type(p))\n    pred, labels = p\n    pred = np.argmax(pred, axis=1)\n\n    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n    recall = recall_score(y_true=labels, y_pred=pred, average='micro')\n    precision = precision_score(y_true=labels, y_pred=pred, average='micro')\n    f1 = f1_score(y_true=labels, y_pred=pred, average='micro')\n\n    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}","metadata":{"execution":{"iopub.status.busy":"2023-02-19T17:09:18.433197Z","iopub.execute_input":"2023-02-19T17:09:18.433590Z","iopub.status.idle":"2023-02-19T17:09:18.442190Z","shell.execute_reply.started":"2023-02-19T17:09:18.433556Z","shell.execute_reply":"2023-02-19T17:09:18.441219Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"### Defining Trainer","metadata":{}},{"cell_type":"code","source":"args = TrainingArguments(\n    output_dir=\"output\",\n    num_train_epochs=5,#20,\n    per_device_train_batch_size=8\n\n)\ntrainer = Trainer(\n    model=model,\n    args=args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    compute_metrics=compute_metrics\n)","metadata":{"execution":{"iopub.status.busy":"2023-02-19T17:11:39.951292Z","iopub.execute_input":"2023-02-19T17:11:39.951712Z","iopub.status.idle":"2023-02-19T17:11:39.975943Z","shell.execute_reply.started":"2023-02-19T17:11:39.951683Z","shell.execute_reply":"2023-02-19T17:11:39.975061Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stderr","text":"PyTorch: setting up devices\nThe default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Training\nusing less number of epochs to save compute. Normally 10 to 20 epochs give good results","metadata":{}},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-02-19T17:11:44.307126Z","iopub.execute_input":"2023-02-19T17:11:44.307537Z","iopub.status.idle":"2023-02-19T17:19:54.315322Z","shell.execute_reply.started":"2023-02-19T17:11:44.307501Z","shell.execute_reply":"2023-02-19T17:19:54.314429Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  FutureWarning,\n***** Running training *****\n  Num examples = 4673\n  Num Epochs = 5\n  Instantaneous batch size per device = 8\n  Total train batch size (w. parallel, distributed & accumulation) = 16\n  Gradient Accumulation steps = 1\n  Total optimization steps = 1465\nAutomatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1465' max='1465' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1465/1465 08:09, Epoch 5/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>0.142700</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.134000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Saving model checkpoint to output/checkpoint-500\nConfiguration saved in output/checkpoint-500/config.json\nModel weights saved in output/checkpoint-500/pytorch_model.bin\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\nSaving model checkpoint to output/checkpoint-1000\nConfiguration saved in output/checkpoint-1000/config.json\nModel weights saved in output/checkpoint-1000/pytorch_model.bin\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n\n\nTraining completed. Do not forget to share your model on huggingface.co/models =)\n\n\n","output_type":"stream"},{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1465, training_loss=0.13370328258735734, metrics={'train_runtime': 489.9753, 'train_samples_per_second': 47.686, 'train_steps_per_second': 2.99, 'total_flos': 1801067872621500.0, 'train_loss': 0.13370328258735734, 'epoch': 5.0})"},"metadata":{}}]},{"cell_type":"markdown","source":"### Evaluating","metadata":{}},{"cell_type":"code","source":"trainer.evaluate()","metadata":{"execution":{"iopub.status.busy":"2023-02-19T17:09:37.122082Z","iopub.execute_input":"2023-02-19T17:09:37.122504Z","iopub.status.idle":"2023-02-19T17:09:42.300636Z","shell.execute_reply.started":"2023-02-19T17:09:37.122471Z","shell.execute_reply":"2023-02-19T17:09:42.299560Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stderr","text":"***** Running Evaluation *****\n  Num examples = 1169\n  Batch size = 16\n/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='74' max='74' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [74/74 00:05]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n","output_type":"stream"},{"name":"stdout","text":"<class 'transformers.trainer_utils.EvalPrediction'>\n","output_type":"stream"},{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 1.3211328983306885,\n 'eval_accuracy': 0.7733105218135158,\n 'eval_precision': 0.7733105218135158,\n 'eval_recall': 0.7733105218135158,\n 'eval_f1': 0.7733105218135158,\n 'eval_runtime': 5.1305,\n 'eval_samples_per_second': 227.854,\n 'eval_steps_per_second': 14.424}"},"metadata":{}}]},{"cell_type":"code","source":"text = \"Tesla has shown increased revenues in earning report\"\ninputs = tokenizer(text,padding = True, truncation = True, return_tensors='pt').to('cuda')\noutputs = model(**inputs)\nprint(outputs)\npredictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\nprint(predictions)\npredictions = predictions.cpu().detach().numpy()\npredictions","metadata":{"execution":{"iopub.status.busy":"2023-02-19T17:22:44.577492Z","iopub.execute_input":"2023-02-19T17:22:44.577899Z","iopub.status.idle":"2023-02-19T17:22:44.663391Z","shell.execute_reply.started":"2023-02-19T17:22:44.577867Z","shell.execute_reply":"2023-02-19T17:22:44.662296Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"SequenceClassifierOutput(loss=None, logits=tensor([[-2.8343, -2.9250,  8.2068]], device='cuda:0',\n       grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\ntensor([[1.6030e-05, 1.4640e-05, 9.9997e-01]], device='cuda:0',\n       grad_fn=<SoftmaxBackward0>)\n","output_type":"stream"},{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"array([[1.6029793e-05, 1.4639594e-05, 9.9996936e-01]], dtype=float32)"},"metadata":{}}]},{"cell_type":"markdown","source":"### Saving model","metadata":{}},{"cell_type":"code","source":"trainer.save_model('CustomModel1')","metadata":{"execution":{"iopub.status.busy":"2023-02-19T17:24:30.084790Z","iopub.execute_input":"2023-02-19T17:24:30.085174Z","iopub.status.idle":"2023-02-19T17:24:30.988441Z","shell.execute_reply.started":"2023-02-19T17:24:30.085142Z","shell.execute_reply":"2023-02-19T17:24:30.987387Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stderr","text":"Saving model checkpoint to CustomModel1\nConfiguration saved in CustomModel1/config.json\nModel weights saved in CustomModel1/pytorch_model.bin\n","output_type":"stream"}]},{"cell_type":"code","source":"# model_2 = BertForSequenceClassification.from_pretrained(\"CustomModel1\")\n# model_2.to('cuda')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# text = \"Tesla has shown increased revenues in earning report\"\n# inputs = tokenizer(text,padding = True, truncation = True, return_tensors='pt').to('cuda')\n# outputs = model_2(**inputs)\n# print(outputs)\n# predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n# print(predictions)\n# predictions = predictions.cpu().detach().numpy()\n# predictions","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}